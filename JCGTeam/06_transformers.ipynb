{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ttx8Jmy6GXf"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srrn7aLV6oni",
    "outputId": "54e6aead-d245-46d7-991a-1006db337eaf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at ./gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"./gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Util Functions"
   ],
   "metadata": {
    "id": "dEV6hZ6yxulK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnIrgOM4bIJ4"
   },
   "outputs": [],
   "source": [
    "def from_raw_to_dataframe(x_raw, y_raw):\n",
    "    tabular_list = []\n",
    "    for i_sample, x in enumerate(x_raw):\n",
    "        for i_time, xx in enumerate(x):\n",
    "            tabular_list.append([i_sample, i_time] + list(xx) + [y_raw[i_sample]])\n",
    "    df_res = pd.DataFrame(tabular_list).rename(columns={\n",
    "        0: 'sample_id',\n",
    "        1: 'time',\n",
    "        2: 'feat_1',\n",
    "        3: 'feat_2',\n",
    "        4: 'feat_3',\n",
    "        5: 'feat_4',\n",
    "        6: 'feat_5',\n",
    "        7: 'feat_6',\n",
    "        8: 'label'}, inplace=False, errors='raise')\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-ffxE8Pa4el"
   },
   "outputs": [],
   "source": [
    "def build_sequences(df):\n",
    "    # Sanity check to avoid runtime errors\n",
    "    #assert window % stride == 0\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for id in df['sample_id'].unique():\n",
    "        # Take only meaningful features\n",
    "        temp = df[df['sample_id'] == id][['feat_1','feat_2','feat_3','feat_4','feat_5','feat_6']].values\n",
    "        # Save the label\n",
    "        label = df[df['sample_id'] == id]['label'].values[0]\n",
    "        labels.append(label)\n",
    "        dataset.append(temp)\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGhNXrmkc_S0"
   },
   "outputs": [],
   "source": [
    "def apply_scaler_to_new_data(x,y,scaler):\n",
    "  x_original_tabular = from_raw_to_dataframe(x, y)\n",
    "  x_original_tabular[['feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6']] = scaler.transform(x_original_tabular[['feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5', 'feat_6']])\n",
    "  agg_x, agg_y = build_sequences(x_original_tabular)\n",
    "  return agg_x, agg_y"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Load"
   ],
   "metadata": {
    "id": "48kdx8F5xw3G"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtr1IqB6JrY9"
   },
   "outputs": [],
   "source": [
    "# load data split\n",
    "with open(\"./gdrive/MyDrive/ann_dataset/HW2/dataUsed/train_test_objKeep9\", \"rb\") as f:\n",
    "  x_train, x_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8dcg3T3KfxP"
   },
   "outputs": [],
   "source": [
    "# load scaler\n",
    "with open(\"./gdrive/MyDrive/ann_dataset/modelss/scaler.p\", \"rb\") as f:\n",
    "  scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k517BZGEKK4-"
   },
   "outputs": [],
   "source": [
    "x_train_norm, y_train_norm = apply_scaler_to_new_data(x_train, y_train, scaler)\n",
    "x_test_norm, y_test_norm = apply_scaler_to_new_data(x_test, y_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pnc1KEM9KXEx"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train_norm)).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_norm, y_test_norm)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqXkL-JN6GXl"
   },
   "outputs": [],
   "source": [
    "n_classes = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "one of this function is probably faulty and creating information leakage from validation to train, main reason for which we preferred to use always the same split loaded from disck"
   ],
   "metadata": {
    "id": "4UgcBt-hzcCH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrPOgA_8yBus"
   },
   "outputs": [],
   "source": [
    "def oversample_data(x_train, y_train):\n",
    "    lengths = []\n",
    "    for label in np.unique(y_train):\n",
    "        lengths.append(np.sum(y_train == label))\n",
    "    id_max = np.argmax(lengths)\n",
    "    max_len = lengths[id_max]\n",
    "\n",
    "    x_train_aug = []\n",
    "    y_train_aug = []\n",
    "    for label in np.unique(y_train):\n",
    "        samples = x_train[y_train == label]\n",
    "        labels = y_train[y_train == label]\n",
    "        indexes = list(np.random.randint(len(samples), size=max_len-len(samples)))\n",
    "        extra_samples = samples[indexes]\n",
    "        extra_labels = labels[indexes]\n",
    "        x_train_aug += list(samples) + list(extra_samples)\n",
    "        y_train_aug += list(labels) + list(extra_labels)\n",
    "\n",
    "    return np.array(x_train_aug), np.array(y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1-TX866yBut"
   },
   "outputs": [],
   "source": [
    "def oversample_data_above_t(x_train, y_train):\n",
    "    x_train_aug = []\n",
    "    y_train_aug = []\n",
    "    for label in np.unique(y_train):\n",
    "        samples = x_train[y_train == label]\n",
    "        labels = y_train[y_train == label]\n",
    "        if len(samples) <= 300:\n",
    "          indexes = list(np.random.randint(len(samples), size=300-len(samples)))\n",
    "          idxs = np.random.choice(indexes, size=(300-len(samples)))\n",
    "          extra_samples = samples[idxs]\n",
    "          extra_labels = labels[indexes]\n",
    "          x_train_aug += list(samples) + list(extra_samples)\n",
    "          y_train_aug += list(labels) + list(extra_labels)\n",
    "        else:\n",
    "            x_train_aug += list(samples)\n",
    "            y_train_aug += list(labels)\n",
    "\n",
    "    return np.array(x_train_aug), np.array(y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCPuTvTUyBut"
   },
   "outputs": [],
   "source": [
    "def undersample_data(x_train, y_train, n_undersampled = 300):\n",
    "    max_len = n_undersampled\n",
    "\n",
    "    x_train_aug = []\n",
    "    y_train_aug = []\n",
    "    for label in np.unique(y_train):\n",
    "        samples = x_train[y_train == label]\n",
    "        labels = y_train[y_train == label]\n",
    "        if len(samples) >= max_len:\n",
    "            indexes = list(np.random.randint(len(samples)))\n",
    "            indexes = list(np.random.choice(indexes, size=max_len, replace=False))\n",
    "            u_samples = samples[indexes]\n",
    "            u_labels = labels[indexes]\n",
    "            x_train_aug += list(u_samples)\n",
    "            y_train_aug += list(u_labels)\n",
    "        else:\n",
    "            x_train_aug += list(samples)\n",
    "            y_train_aug += list(labels)\n",
    "\n",
    "    return np.array(x_train_aug), np.array(y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AwKwIphyBut"
   },
   "outputs": [],
   "source": [
    "def print_representance(y):\n",
    "    tot = len(y)\n",
    "    strings = []\n",
    "    lengths = []\n",
    "    for label in np.unique(y):\n",
    "        n = np.sum(y == label)\n",
    "        strings.append(f\"class-{label}  -> \\t{n}\\t\\t{n / tot:.2}\\t\\t{(n / tot * 100):.4}%\")\n",
    "        lengths.append(n)\\\n",
    "\n",
    "    for i in np.argsort(lengths)[::-1]:\n",
    "        print(strings[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transoformer build functions"
   ],
   "metadata": {
    "id": "f2_47jejx1mD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOldj4kC6GXm"
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igZcSg3C6GX5"
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        input_shape,\n",
    "        head_size,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_transformer_blocks,\n",
    "        mlp_units,\n",
    "        dropout=0,\n",
    "        mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\", kernel_initializer = tf.keras.initializers.HeNormal())(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\", kernel_initializer = tf.keras.initializers.HeNormal())(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "mCIAbinC6GY5"
   },
   "source": [
    "# Commented faulty code of transformer scoring 0.8 bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "G_ibI4me6GZF",
    "outputId": "e329a752-e6c2-41b9-f9f9-b3aaf00c47e1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'keep = [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 9]  # classes to keep in the training\\n\\nx_tmp = []\\ny_tmp = []\\nfor i, y in enumerate(y_original):\\n    if y in keep:\\n        x_tmp.append(x_original[i])\\n        y_tmp.append(y)\\nx_original = np.array(x_tmp)\\ny_original = np.array(y_tmp)\\n\\nprint(x_original.shape)\\nprint(y_original.shape)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "\"\"\"x_original = np.load('./gdrive/MyDrive/ann_dataset/HW2/x_train.npy') # Shape: (2429, 36, 6)\n",
    "y_original = np.load('./gdrive/MyDrive/ann_dataset/HW2/y_train.npy') # Labels\"\"\"\n",
    "\n",
    "\"\"\"keep = [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 9]  # classes to keep in the training\n",
    "\n",
    "x_tmp = []\n",
    "y_tmp = []\n",
    "for i, y in enumerate(y_original):\n",
    "    if y in keep:\n",
    "        x_tmp.append(x_original[i])\n",
    "        y_tmp.append(y)\n",
    "x_original = np.array(x_tmp)\n",
    "y_original = np.array(y_tmp)\n",
    "\n",
    "print(x_original.shape)\n",
    "print(y_original.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IiSB2HQ6GZI"
   },
   "outputs": [],
   "source": [
    "\"\"\"READ_FROM_LOCAL = False\n",
    "\n",
    "if not READ_FROM_LOCAL:\n",
    "    train_test_trans_obj = train_test_split(x_original, y_original, test_size=0.2, shuffle=True)\n",
    "    x, x_test, y, y_test = train_test_trans_obj\n",
    "\n",
    "   # with open(\"./dataUsed/train_test_trans_obj\", \"wb\") as f:\n",
    "    #    pickle.dump(train_test_trans_obj, f)\n",
    "else:\n",
    "    with open(\"./dataUsed/train_test_trans_obj\", \"3b\") as f:\n",
    "        x, x_test, y, y_test = pickle.load(f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9rt7Hga6GZR",
    "outputId": "4e0ed4fc-c1da-47bc-9432-18c254f803e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class-9  -> \t777\t\t0.32\t\t31.99%\n",
      "class-3  -> \t381\t\t0.16\t\t15.69%\n",
      "class-6  -> \t313\t\t0.13\t\t12.89%\n",
      "class-2  -> \t270\t\t0.11\t\t11.12%\n",
      "class-5  -> \t153\t\t0.063\t\t6.299%\n",
      "class-1  -> \t123\t\t0.051\t\t5.064%\n",
      "class-8  -> \t120\t\t0.049\t\t4.94%\n",
      "class-10  -> \t77\t\t0.032\t\t3.17%\n",
      "class-7  -> \t68\t\t0.028\t\t2.8%\n",
      "class-4  -> \t62\t\t0.026\t\t2.552%\n",
      "class-11  -> \t51\t\t0.021\t\t2.1%\n",
      "class-0  -> \t34\t\t0.014\t\t1.4%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print_representance(y_original)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyumqxWo6GZS",
    "outputId": "d1b4a513-e4e7-4801-8e33-b2dd053076a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3920, 36, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x, y = undersample_data(x_original, y_original, n_undersampled=300) # first limit the classes undersampling\n",
    "\"\"\"x, y = oversample_data_above_t(x, y)  # oversample low frequency classes\n",
    "\n",
    "idxs = np.arange(len(y))\n",
    "np.random.shuffle(idxs)\n",
    "x = x[idxs]\n",
    "y = y[idxs]\n",
    "x.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwWwsCoH8Orv",
    "outputId": "3d21eb1c-221f-4a5b-9ccc-ea3567a3e072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class-9  -> \t617\t\t0.16\t\t15.72%\n",
      "class-3  -> \t309\t\t0.079\t\t7.871%\n",
      "class-11  -> \t300\t\t0.076\t\t7.641%\n",
      "class-10  -> \t300\t\t0.076\t\t7.641%\n",
      "class-8  -> \t300\t\t0.076\t\t7.641%\n",
      "class-7  -> \t300\t\t0.076\t\t7.641%\n",
      "class-6  -> \t300\t\t0.076\t\t7.641%\n",
      "class-5  -> \t300\t\t0.076\t\t7.641%\n",
      "class-4  -> \t300\t\t0.076\t\t7.641%\n",
      "class-2  -> \t300\t\t0.076\t\t7.641%\n",
      "class-1  -> \t300\t\t0.076\t\t7.641%\n",
      "class-0  -> \t300\t\t0.076\t\t7.641%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print_representance(y)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hgmQl29Dl83"
   },
   "outputs": [],
   "source": [
    "\"\"\"KEEP_ONE_FEATURE = True\n",
    "if KEEP_ONE_FEATURE:\n",
    "  id = 3\n",
    "  x = x[:, :,[id]]\n",
    "  x_test = x_test[:, :,[id]]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qerSMZ-x6GZX"
   },
   "outputs": [],
   "source": [
    "\"\"\"test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "BATCH_SIZE = 128\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compilation and training"
   ],
   "metadata": {
    "id": "t5O5b1ATzG6K"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxw1lEY46GZX",
    "outputId": "2335b618-900c-4b8a-f430-cc80ed2ef554"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 36, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_152 (Layer  (None, 36, 6)       12          ['input_9[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_76 (Multi  (None, 36, 6)       221190      ['layer_normalization_152[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " dropout_160 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_76[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_152 (TFOp  (None, 36, 6)       0           ['dropout_160[0][0]',            \n",
      " Lambda)                                                          'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_153 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_152[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_152 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " dropout_161 (Dropout)          (None, 36, 32)       0           ['conv1d_152[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_153 (Conv1D)            (None, 36, 6)        198         ['dropout_161[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_153 (TFOp  (None, 36, 6)       0           ['conv1d_153[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_152[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_154 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_153[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_77 (Multi  (None, 36, 6)       221190      ['layer_normalization_154[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " dropout_162 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_77[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_154 (TFOp  (None, 36, 6)       0           ['dropout_162[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_153[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_155 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_154[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_154 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " dropout_163 (Dropout)          (None, 36, 32)       0           ['conv1d_154[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_155 (Conv1D)            (None, 36, 6)        198         ['dropout_163[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_155 (TFOp  (None, 36, 6)       0           ['conv1d_155[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_154[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_156 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_155[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_78 (Multi  (None, 36, 6)       221190      ['layer_normalization_156[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " dropout_164 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_78[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_156 (TFOp  (None, 36, 6)       0           ['dropout_164[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_155[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_157 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_156[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_156 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " dropout_165 (Dropout)          (None, 36, 32)       0           ['conv1d_156[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_157 (Conv1D)            (None, 36, 6)        198         ['dropout_165[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_157 (TFOp  (None, 36, 6)       0           ['conv1d_157[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_156[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_158 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_157[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_79 (Multi  (None, 36, 6)       221190      ['layer_normalization_158[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " dropout_166 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_79[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_158 (TFOp  (None, 36, 6)       0           ['dropout_166[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_157[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_159 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_158[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_158 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " dropout_167 (Dropout)          (None, 36, 32)       0           ['conv1d_158[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_159 (Conv1D)            (None, 36, 6)        198         ['dropout_167[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_159 (TFOp  (None, 36, 6)       0           ['conv1d_159[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_158[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_160 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_159[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_80 (Multi  (None, 36, 6)       221190      ['layer_normalization_160[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " dropout_168 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_80[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_160 (TFOp  (None, 36, 6)       0           ['dropout_168[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_159[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_161 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_160[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_160 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " dropout_169 (Dropout)          (None, 36, 32)       0           ['conv1d_160[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_161 (Conv1D)            (None, 36, 6)        198         ['dropout_169[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_161 (TFOp  (None, 36, 6)       0           ['conv1d_161[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_160[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_162 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_161[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_81 (Multi  (None, 36, 6)       221190      ['layer_normalization_162[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " dropout_170 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_81[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_162 (TFOp  (None, 36, 6)       0           ['dropout_170[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_161[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_163 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_162[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_162 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " dropout_171 (Dropout)          (None, 36, 32)       0           ['conv1d_162[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_163 (Conv1D)            (None, 36, 6)        198         ['dropout_171[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_163 (TFOp  (None, 36, 6)       0           ['conv1d_163[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_162[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_164 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_163[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_82 (Multi  (None, 36, 6)       221190      ['layer_normalization_164[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " dropout_172 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_82[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_164 (TFOp  (None, 36, 6)       0           ['dropout_172[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_163[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_165 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_164[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_164 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " dropout_173 (Dropout)          (None, 36, 32)       0           ['conv1d_164[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_165 (Conv1D)            (None, 36, 6)        198         ['dropout_173[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_165 (TFOp  (None, 36, 6)       0           ['conv1d_165[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_164[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_166 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_165[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_83 (Multi  (None, 36, 6)       221190      ['layer_normalization_166[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " dropout_174 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_83[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_166 (TFOp  (None, 36, 6)       0           ['dropout_174[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_165[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_167 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_166[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_166 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " dropout_175 (Dropout)          (None, 36, 32)       0           ['conv1d_166[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_167 (Conv1D)            (None, 36, 6)        198         ['dropout_175[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_167 (TFOp  (None, 36, 6)       0           ['conv1d_167[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_166[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_168 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_167[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_84 (Multi  (None, 36, 6)       221190      ['layer_normalization_168[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " dropout_176 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_84[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_168 (TFOp  (None, 36, 6)       0           ['dropout_176[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_167[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_169 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_168[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_168 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " dropout_177 (Dropout)          (None, 36, 32)       0           ['conv1d_168[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_169 (Conv1D)            (None, 36, 6)        198         ['dropout_177[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_169 (TFOp  (None, 36, 6)       0           ['conv1d_169[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_168[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_170 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_169[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_85 (Multi  (None, 36, 6)       221190      ['layer_normalization_170[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " dropout_178 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_85[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_170 (TFOp  (None, 36, 6)       0           ['dropout_178[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_169[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_171 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_170[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_170 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " dropout_179 (Dropout)          (None, 36, 32)       0           ['conv1d_170[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_171 (Conv1D)            (None, 36, 6)        198         ['dropout_179[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_171 (TFOp  (None, 36, 6)       0           ['conv1d_171[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_170[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_172 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_171[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_86 (Multi  (None, 36, 6)       221190      ['layer_normalization_172[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " dropout_180 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_86[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_172 (TFOp  (None, 36, 6)       0           ['dropout_180[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_171[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_173 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_172[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_172 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " dropout_181 (Dropout)          (None, 36, 32)       0           ['conv1d_172[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_173 (Conv1D)            (None, 36, 6)        198         ['dropout_181[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_173 (TFOp  (None, 36, 6)       0           ['conv1d_173[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_172[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_174 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_173[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_87 (Multi  (None, 36, 6)       221190      ['layer_normalization_174[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " dropout_182 (Dropout)          (None, 36, 6)        0           ['multi_head_attention_87[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_174 (TFOp  (None, 36, 6)       0           ['dropout_182[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_173[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_175 (Layer  (None, 36, 6)       12          ['tf.__operators__.add_174[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_174 (Conv1D)            (None, 36, 32)       224         ['layer_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " dropout_183 (Dropout)          (None, 36, 32)       0           ['conv1d_174[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_175 (Conv1D)            (None, 36, 6)        198         ['dropout_183[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_175 (TFOp  (None, 36, 6)       0           ['conv1d_175[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_174[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 36)          0           ['tf.__operators__.add_175[0][0]'\n",
      " obalAveragePooling1D)                                           ]                                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          4736        ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_184 (Dropout)          (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 12)           1548        ['dropout_184[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,665,916\n",
      "Trainable params: 2,665,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train_norm.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=32,\n",
    "    ff_dim=32,\n",
    "    num_transformer_blocks=12,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "\"\"\"model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    ")\"\"\"\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(5e-4),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',patience=100, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XhUqj3Y6GZY",
    "outputId": "a334fdcb-a4af-49fa-c230-6f59388f877d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3000\n",
      "16/16 [==============================] - 14s 222ms/step - loss: 35.1978 - sparse_categorical_accuracy: 0.0623 - val_loss: 22.8019 - val_sparse_categorical_accuracy: 0.0679\n",
      "Epoch 2/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 29.9209 - sparse_categorical_accuracy: 0.0633 - val_loss: 18.8776 - val_sparse_categorical_accuracy: 0.0905\n",
      "Epoch 3/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 24.0561 - sparse_categorical_accuracy: 0.0870 - val_loss: 16.3482 - val_sparse_categorical_accuracy: 0.0947\n",
      "Epoch 4/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 23.4871 - sparse_categorical_accuracy: 0.0808 - val_loss: 14.5188 - val_sparse_categorical_accuracy: 0.1337\n",
      "Epoch 5/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 19.6646 - sparse_categorical_accuracy: 0.0973 - val_loss: 12.9360 - val_sparse_categorical_accuracy: 0.1296\n",
      "Epoch 6/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 18.6770 - sparse_categorical_accuracy: 0.1143 - val_loss: 11.8256 - val_sparse_categorical_accuracy: 0.1749\n",
      "Epoch 7/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 15.4552 - sparse_categorical_accuracy: 0.1091 - val_loss: 11.1148 - val_sparse_categorical_accuracy: 0.1708\n",
      "Epoch 8/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 14.7181 - sparse_categorical_accuracy: 0.1086 - val_loss: 10.7680 - val_sparse_categorical_accuracy: 0.1770\n",
      "Epoch 9/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 12.9435 - sparse_categorical_accuracy: 0.1034 - val_loss: 10.6339 - val_sparse_categorical_accuracy: 0.1708\n",
      "Epoch 10/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 11.5748 - sparse_categorical_accuracy: 0.1225 - val_loss: 10.5503 - val_sparse_categorical_accuracy: 0.1481\n",
      "Epoch 11/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 12.6528 - sparse_categorical_accuracy: 0.1122 - val_loss: 10.2029 - val_sparse_categorical_accuracy: 0.1049\n",
      "Epoch 12/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 12.3737 - sparse_categorical_accuracy: 0.1117 - val_loss: 9.6430 - val_sparse_categorical_accuracy: 0.1728\n",
      "Epoch 13/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 11.5674 - sparse_categorical_accuracy: 0.1261 - val_loss: 9.0093 - val_sparse_categorical_accuracy: 0.2202\n",
      "Epoch 14/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 9.7622 - sparse_categorical_accuracy: 0.1189 - val_loss: 8.7392 - val_sparse_categorical_accuracy: 0.2222\n",
      "Epoch 15/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 9.1660 - sparse_categorical_accuracy: 0.1405 - val_loss: 9.5267 - val_sparse_categorical_accuracy: 0.0844\n",
      "Epoch 16/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 10.0813 - sparse_categorical_accuracy: 0.1163 - val_loss: 8.7424 - val_sparse_categorical_accuracy: 0.1975\n",
      "Epoch 17/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 10.1336 - sparse_categorical_accuracy: 0.1379 - val_loss: 8.6148 - val_sparse_categorical_accuracy: 0.2222\n",
      "Epoch 18/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 8.3758 - sparse_categorical_accuracy: 0.1518 - val_loss: 8.4517 - val_sparse_categorical_accuracy: 0.1626\n",
      "Epoch 19/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 7.5369 - sparse_categorical_accuracy: 0.1575 - val_loss: 8.3021 - val_sparse_categorical_accuracy: 0.1749\n",
      "Epoch 20/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 7.8310 - sparse_categorical_accuracy: 0.1374 - val_loss: 8.2655 - val_sparse_categorical_accuracy: 0.1996\n",
      "Epoch 21/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 8.6264 - sparse_categorical_accuracy: 0.1647 - val_loss: 8.1992 - val_sparse_categorical_accuracy: 0.2654\n",
      "Epoch 22/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 7.8749 - sparse_categorical_accuracy: 0.1812 - val_loss: 8.2178 - val_sparse_categorical_accuracy: 0.2366\n",
      "Epoch 23/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 7.8889 - sparse_categorical_accuracy: 0.1518 - val_loss: 8.0913 - val_sparse_categorical_accuracy: 0.2757\n",
      "Epoch 24/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 7.1244 - sparse_categorical_accuracy: 0.1529 - val_loss: 8.0349 - val_sparse_categorical_accuracy: 0.2634\n",
      "Epoch 25/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 7.0401 - sparse_categorical_accuracy: 0.1904 - val_loss: 7.9874 - val_sparse_categorical_accuracy: 0.2798\n",
      "Epoch 26/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 7.2325 - sparse_categorical_accuracy: 0.1822 - val_loss: 7.9342 - val_sparse_categorical_accuracy: 0.2901\n",
      "Epoch 27/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 7.0439 - sparse_categorical_accuracy: 0.1879 - val_loss: 7.7705 - val_sparse_categorical_accuracy: 0.2901\n",
      "Epoch 28/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 6.5985 - sparse_categorical_accuracy: 0.2038 - val_loss: 7.6371 - val_sparse_categorical_accuracy: 0.3066\n",
      "Epoch 29/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 6.4472 - sparse_categorical_accuracy: 0.1879 - val_loss: 7.7319 - val_sparse_categorical_accuracy: 0.3148\n",
      "Epoch 30/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 6.6851 - sparse_categorical_accuracy: 0.2187 - val_loss: 7.8507 - val_sparse_categorical_accuracy: 0.3313\n",
      "Epoch 31/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 6.3651 - sparse_categorical_accuracy: 0.2254 - val_loss: 7.8671 - val_sparse_categorical_accuracy: 0.3272\n",
      "Epoch 32/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 6.3374 - sparse_categorical_accuracy: 0.2141 - val_loss: 7.4300 - val_sparse_categorical_accuracy: 0.3189\n",
      "Epoch 33/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 6.4613 - sparse_categorical_accuracy: 0.2321 - val_loss: 7.3379 - val_sparse_categorical_accuracy: 0.3436\n",
      "Epoch 34/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 6.1438 - sparse_categorical_accuracy: 0.2162 - val_loss: 7.2248 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 35/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 5.7744 - sparse_categorical_accuracy: 0.2553 - val_loss: 7.1226 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 36/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 6.1014 - sparse_categorical_accuracy: 0.2362 - val_loss: 7.2748 - val_sparse_categorical_accuracy: 0.3436\n",
      "Epoch 37/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 6.1150 - sparse_categorical_accuracy: 0.2398 - val_loss: 7.3041 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 38/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 5.6480 - sparse_categorical_accuracy: 0.2542 - val_loss: 7.3239 - val_sparse_categorical_accuracy: 0.3416\n",
      "Epoch 39/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 5.8008 - sparse_categorical_accuracy: 0.2440 - val_loss: 7.0792 - val_sparse_categorical_accuracy: 0.3189\n",
      "Epoch 40/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.8740 - sparse_categorical_accuracy: 0.2470 - val_loss: 7.0489 - val_sparse_categorical_accuracy: 0.3086\n",
      "Epoch 41/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 5.3075 - sparse_categorical_accuracy: 0.2383 - val_loss: 7.1141 - val_sparse_categorical_accuracy: 0.3107\n",
      "Epoch 42/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 5.1352 - sparse_categorical_accuracy: 0.2563 - val_loss: 7.1001 - val_sparse_categorical_accuracy: 0.3107\n",
      "Epoch 43/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 4.9088 - sparse_categorical_accuracy: 0.2465 - val_loss: 6.9998 - val_sparse_categorical_accuracy: 0.3210\n",
      "Epoch 44/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.8130 - sparse_categorical_accuracy: 0.2311 - val_loss: 6.8524 - val_sparse_categorical_accuracy: 0.3272\n",
      "Epoch 45/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.6688 - sparse_categorical_accuracy: 0.2882 - val_loss: 6.8937 - val_sparse_categorical_accuracy: 0.3395\n",
      "Epoch 46/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 5.1715 - sparse_categorical_accuracy: 0.2810 - val_loss: 7.0460 - val_sparse_categorical_accuracy: 0.3313\n",
      "Epoch 47/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 5.0758 - sparse_categorical_accuracy: 0.2630 - val_loss: 6.8603 - val_sparse_categorical_accuracy: 0.3395\n",
      "Epoch 48/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 5.0257 - sparse_categorical_accuracy: 0.2867 - val_loss: 6.8478 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 49/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.8177 - sparse_categorical_accuracy: 0.2892 - val_loss: 6.4944 - val_sparse_categorical_accuracy: 0.3436\n",
      "Epoch 50/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.4503 - sparse_categorical_accuracy: 0.2918 - val_loss: 6.5981 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 51/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 4.9451 - sparse_categorical_accuracy: 0.3176 - val_loss: 6.6160 - val_sparse_categorical_accuracy: 0.3724\n",
      "Epoch 52/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.4877 - sparse_categorical_accuracy: 0.3031 - val_loss: 6.4967 - val_sparse_categorical_accuracy: 0.3580\n",
      "Epoch 53/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.6933 - sparse_categorical_accuracy: 0.2980 - val_loss: 6.5294 - val_sparse_categorical_accuracy: 0.3477\n",
      "Epoch 54/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.2941 - sparse_categorical_accuracy: 0.2944 - val_loss: 6.6344 - val_sparse_categorical_accuracy: 0.3642\n",
      "Epoch 55/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.3992 - sparse_categorical_accuracy: 0.3037 - val_loss: 6.6410 - val_sparse_categorical_accuracy: 0.3724\n",
      "Epoch 56/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 4.3177 - sparse_categorical_accuracy: 0.3098 - val_loss: 6.6018 - val_sparse_categorical_accuracy: 0.3765\n",
      "Epoch 57/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.9759 - sparse_categorical_accuracy: 0.3227 - val_loss: 6.6271 - val_sparse_categorical_accuracy: 0.3724\n",
      "Epoch 58/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.0358 - sparse_categorical_accuracy: 0.3268 - val_loss: 6.6967 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 59/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 4.9055 - sparse_categorical_accuracy: 0.3057 - val_loss: 6.8086 - val_sparse_categorical_accuracy: 0.3786\n",
      "Epoch 60/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 3.9270 - sparse_categorical_accuracy: 0.3371 - val_loss: 6.8202 - val_sparse_categorical_accuracy: 0.3827\n",
      "Epoch 61/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 3.6347 - sparse_categorical_accuracy: 0.3371 - val_loss: 6.7715 - val_sparse_categorical_accuracy: 0.3868\n",
      "Epoch 62/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.0521 - sparse_categorical_accuracy: 0.3350 - val_loss: 6.6206 - val_sparse_categorical_accuracy: 0.3848\n",
      "Epoch 63/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.5172 - sparse_categorical_accuracy: 0.3196 - val_loss: 6.4688 - val_sparse_categorical_accuracy: 0.3724\n",
      "Epoch 64/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.5533 - sparse_categorical_accuracy: 0.3299 - val_loss: 6.4371 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 65/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.5896 - sparse_categorical_accuracy: 0.3237 - val_loss: 6.3957 - val_sparse_categorical_accuracy: 0.3745\n",
      "Epoch 66/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.6739 - sparse_categorical_accuracy: 0.3423 - val_loss: 6.2827 - val_sparse_categorical_accuracy: 0.3745\n",
      "Epoch 67/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.7889 - sparse_categorical_accuracy: 0.3253 - val_loss: 6.1120 - val_sparse_categorical_accuracy: 0.3745\n",
      "Epoch 68/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.9594 - sparse_categorical_accuracy: 0.3273 - val_loss: 6.1028 - val_sparse_categorical_accuracy: 0.3683\n",
      "Epoch 69/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.6625 - sparse_categorical_accuracy: 0.3263 - val_loss: 6.1845 - val_sparse_categorical_accuracy: 0.3745\n",
      "Epoch 70/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 3.5950 - sparse_categorical_accuracy: 0.3423 - val_loss: 6.1648 - val_sparse_categorical_accuracy: 0.3909\n",
      "Epoch 71/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.0438 - sparse_categorical_accuracy: 0.3546 - val_loss: 6.1032 - val_sparse_categorical_accuracy: 0.3827\n",
      "Epoch 72/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.4052 - sparse_categorical_accuracy: 0.3325 - val_loss: 5.9595 - val_sparse_categorical_accuracy: 0.3827\n",
      "Epoch 73/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.4623 - sparse_categorical_accuracy: 0.3531 - val_loss: 5.6703 - val_sparse_categorical_accuracy: 0.3807\n",
      "Epoch 74/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.7710 - sparse_categorical_accuracy: 0.3392 - val_loss: 5.5294 - val_sparse_categorical_accuracy: 0.3745\n",
      "Epoch 75/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.3761 - sparse_categorical_accuracy: 0.3459 - val_loss: 5.6199 - val_sparse_categorical_accuracy: 0.3745\n",
      "Epoch 76/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.5679 - sparse_categorical_accuracy: 0.3314 - val_loss: 5.6843 - val_sparse_categorical_accuracy: 0.3848\n",
      "Epoch 77/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.5686 - sparse_categorical_accuracy: 0.3572 - val_loss: 5.6578 - val_sparse_categorical_accuracy: 0.3868\n",
      "Epoch 78/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.3857 - sparse_categorical_accuracy: 0.3567 - val_loss: 5.7712 - val_sparse_categorical_accuracy: 0.3909\n",
      "Epoch 79/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 4.0254 - sparse_categorical_accuracy: 0.3551 - val_loss: 5.7487 - val_sparse_categorical_accuracy: 0.3909\n",
      "Epoch 80/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.4309 - sparse_categorical_accuracy: 0.3479 - val_loss: 5.7412 - val_sparse_categorical_accuracy: 0.3807\n",
      "Epoch 81/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.5451 - sparse_categorical_accuracy: 0.3320 - val_loss: 5.6861 - val_sparse_categorical_accuracy: 0.3786\n",
      "Epoch 82/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.2947 - sparse_categorical_accuracy: 0.3459 - val_loss: 5.6803 - val_sparse_categorical_accuracy: 0.3704\n",
      "Epoch 83/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.3455 - sparse_categorical_accuracy: 0.3428 - val_loss: 5.7152 - val_sparse_categorical_accuracy: 0.3848\n",
      "Epoch 84/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 3.1890 - sparse_categorical_accuracy: 0.3603 - val_loss: 5.6637 - val_sparse_categorical_accuracy: 0.3971\n",
      "Epoch 85/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.6342 - sparse_categorical_accuracy: 0.3664 - val_loss: 5.6642 - val_sparse_categorical_accuracy: 0.3889\n",
      "Epoch 86/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.2826 - sparse_categorical_accuracy: 0.3500 - val_loss: 5.5026 - val_sparse_categorical_accuracy: 0.3848\n",
      "Epoch 87/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 3.0576 - sparse_categorical_accuracy: 0.3628 - val_loss: 5.4400 - val_sparse_categorical_accuracy: 0.4053\n",
      "Epoch 88/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.0625 - sparse_categorical_accuracy: 0.3608 - val_loss: 5.3376 - val_sparse_categorical_accuracy: 0.3971\n",
      "Epoch 89/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 3.0509 - sparse_categorical_accuracy: 0.3788 - val_loss: 5.3202 - val_sparse_categorical_accuracy: 0.4053\n",
      "Epoch 90/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 3.5026 - sparse_categorical_accuracy: 0.3680 - val_loss: 5.2845 - val_sparse_categorical_accuracy: 0.4074\n",
      "Epoch 91/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.9741 - sparse_categorical_accuracy: 0.3886 - val_loss: 5.1978 - val_sparse_categorical_accuracy: 0.4115\n",
      "Epoch 92/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.0431 - sparse_categorical_accuracy: 0.3814 - val_loss: 5.2059 - val_sparse_categorical_accuracy: 0.3971\n",
      "Epoch 93/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.8882 - sparse_categorical_accuracy: 0.3767 - val_loss: 5.0600 - val_sparse_categorical_accuracy: 0.4136\n",
      "Epoch 94/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 3.0728 - sparse_categorical_accuracy: 0.3932 - val_loss: 5.0891 - val_sparse_categorical_accuracy: 0.4012\n",
      "Epoch 95/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.8205 - sparse_categorical_accuracy: 0.3978 - val_loss: 5.0861 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 96/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.9149 - sparse_categorical_accuracy: 0.3824 - val_loss: 5.0622 - val_sparse_categorical_accuracy: 0.4095\n",
      "Epoch 97/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.9475 - sparse_categorical_accuracy: 0.3901 - val_loss: 4.8628 - val_sparse_categorical_accuracy: 0.4259\n",
      "Epoch 98/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.8267 - sparse_categorical_accuracy: 0.4030 - val_loss: 4.8281 - val_sparse_categorical_accuracy: 0.4115\n",
      "Epoch 99/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.8517 - sparse_categorical_accuracy: 0.3778 - val_loss: 4.8338 - val_sparse_categorical_accuracy: 0.4136\n",
      "Epoch 100/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.8109 - sparse_categorical_accuracy: 0.3994 - val_loss: 4.8375 - val_sparse_categorical_accuracy: 0.4198\n",
      "Epoch 101/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 3.2855 - sparse_categorical_accuracy: 0.3911 - val_loss: 4.7504 - val_sparse_categorical_accuracy: 0.4300\n",
      "Epoch 102/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.6892 - sparse_categorical_accuracy: 0.4081 - val_loss: 4.8532 - val_sparse_categorical_accuracy: 0.4074\n",
      "Epoch 103/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5948 - sparse_categorical_accuracy: 0.3984 - val_loss: 4.6553 - val_sparse_categorical_accuracy: 0.4239\n",
      "Epoch 104/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 3.0661 - sparse_categorical_accuracy: 0.3999 - val_loss: 4.5460 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 105/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.9528 - sparse_categorical_accuracy: 0.3881 - val_loss: 4.4881 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 106/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.7111 - sparse_categorical_accuracy: 0.3762 - val_loss: 4.5046 - val_sparse_categorical_accuracy: 0.4198\n",
      "Epoch 107/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.7603 - sparse_categorical_accuracy: 0.3984 - val_loss: 4.4809 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 108/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.8854 - sparse_categorical_accuracy: 0.3870 - val_loss: 4.4882 - val_sparse_categorical_accuracy: 0.4280\n",
      "Epoch 109/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5553 - sparse_categorical_accuracy: 0.4189 - val_loss: 4.4524 - val_sparse_categorical_accuracy: 0.4259\n",
      "Epoch 110/3000\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 2.7642 - sparse_categorical_accuracy: 0.3942 - val_loss: 4.5932 - val_sparse_categorical_accuracy: 0.4321\n",
      "Epoch 111/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.6229 - sparse_categorical_accuracy: 0.4056 - val_loss: 4.7137 - val_sparse_categorical_accuracy: 0.4115\n",
      "Epoch 112/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5770 - sparse_categorical_accuracy: 0.3999 - val_loss: 4.5941 - val_sparse_categorical_accuracy: 0.4218\n",
      "Epoch 113/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.5052 - sparse_categorical_accuracy: 0.4148 - val_loss: 4.6301 - val_sparse_categorical_accuracy: 0.4198\n",
      "Epoch 114/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5585 - sparse_categorical_accuracy: 0.4030 - val_loss: 4.5470 - val_sparse_categorical_accuracy: 0.4198\n",
      "Epoch 115/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.4658 - sparse_categorical_accuracy: 0.3911 - val_loss: 4.7305 - val_sparse_categorical_accuracy: 0.4198\n",
      "Epoch 116/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.9988 - sparse_categorical_accuracy: 0.4035 - val_loss: 4.6434 - val_sparse_categorical_accuracy: 0.4218\n",
      "Epoch 117/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5208 - sparse_categorical_accuracy: 0.3984 - val_loss: 4.5600 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 118/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5392 - sparse_categorical_accuracy: 0.3922 - val_loss: 4.6896 - val_sparse_categorical_accuracy: 0.4300\n",
      "Epoch 119/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.5390 - sparse_categorical_accuracy: 0.4246 - val_loss: 4.8366 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 120/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5889 - sparse_categorical_accuracy: 0.4097 - val_loss: 4.8593 - val_sparse_categorical_accuracy: 0.4218\n",
      "Epoch 121/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.6030 - sparse_categorical_accuracy: 0.4189 - val_loss: 4.9135 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 122/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5242 - sparse_categorical_accuracy: 0.4308 - val_loss: 4.9997 - val_sparse_categorical_accuracy: 0.4156\n",
      "Epoch 123/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.3689 - sparse_categorical_accuracy: 0.4282 - val_loss: 4.9960 - val_sparse_categorical_accuracy: 0.4362\n",
      "Epoch 124/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.5370 - sparse_categorical_accuracy: 0.4117 - val_loss: 4.9811 - val_sparse_categorical_accuracy: 0.4239\n",
      "Epoch 125/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.3469 - sparse_categorical_accuracy: 0.4282 - val_loss: 5.0429 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 126/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.3090 - sparse_categorical_accuracy: 0.4282 - val_loss: 5.0931 - val_sparse_categorical_accuracy: 0.4177\n",
      "Epoch 127/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.4417 - sparse_categorical_accuracy: 0.4364 - val_loss: 5.0716 - val_sparse_categorical_accuracy: 0.4259\n",
      "Epoch 128/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.2184 - sparse_categorical_accuracy: 0.4339 - val_loss: 4.9767 - val_sparse_categorical_accuracy: 0.4280\n",
      "Epoch 129/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.3953 - sparse_categorical_accuracy: 0.4395 - val_loss: 5.0128 - val_sparse_categorical_accuracy: 0.4280\n",
      "Epoch 130/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.3873 - sparse_categorical_accuracy: 0.4395 - val_loss: 5.0181 - val_sparse_categorical_accuracy: 0.4239\n",
      "Epoch 131/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.2490 - sparse_categorical_accuracy: 0.4400 - val_loss: 4.9959 - val_sparse_categorical_accuracy: 0.4321\n",
      "Epoch 132/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.2355 - sparse_categorical_accuracy: 0.4323 - val_loss: 4.9537 - val_sparse_categorical_accuracy: 0.4259\n",
      "Epoch 133/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.2941 - sparse_categorical_accuracy: 0.4375 - val_loss: 4.8870 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 134/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.1345 - sparse_categorical_accuracy: 0.4385 - val_loss: 4.7829 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 135/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.1285 - sparse_categorical_accuracy: 0.4447 - val_loss: 4.7467 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 136/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.4413 - sparse_categorical_accuracy: 0.4359 - val_loss: 4.7781 - val_sparse_categorical_accuracy: 0.4630\n",
      "Epoch 137/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.2606 - sparse_categorical_accuracy: 0.4349 - val_loss: 4.7252 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 138/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.1844 - sparse_categorical_accuracy: 0.4426 - val_loss: 4.7218 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 139/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.9904 - sparse_categorical_accuracy: 0.4632 - val_loss: 4.6927 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 140/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.1568 - sparse_categorical_accuracy: 0.4508 - val_loss: 4.7017 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 141/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.4433 - sparse_categorical_accuracy: 0.4488 - val_loss: 4.6960 - val_sparse_categorical_accuracy: 0.4342\n",
      "Epoch 142/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0633 - sparse_categorical_accuracy: 0.4421 - val_loss: 4.7888 - val_sparse_categorical_accuracy: 0.4362\n",
      "Epoch 143/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0919 - sparse_categorical_accuracy: 0.4452 - val_loss: 4.8180 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 144/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0892 - sparse_categorical_accuracy: 0.4514 - val_loss: 4.8121 - val_sparse_categorical_accuracy: 0.4506\n",
      "Epoch 145/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.1643 - sparse_categorical_accuracy: 0.4349 - val_loss: 4.8137 - val_sparse_categorical_accuracy: 0.4506\n",
      "Epoch 146/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.2259 - sparse_categorical_accuracy: 0.4390 - val_loss: 4.6773 - val_sparse_categorical_accuracy: 0.4362\n",
      "Epoch 147/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.0926 - sparse_categorical_accuracy: 0.4534 - val_loss: 4.6638 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 148/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0137 - sparse_categorical_accuracy: 0.4596 - val_loss: 4.6737 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 149/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.0677 - sparse_categorical_accuracy: 0.4720 - val_loss: 4.6162 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 150/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.8496 - sparse_categorical_accuracy: 0.4756 - val_loss: 4.6050 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 151/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0532 - sparse_categorical_accuracy: 0.4678 - val_loss: 4.5469 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 152/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8935 - sparse_categorical_accuracy: 0.4792 - val_loss: 4.5120 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 153/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.9634 - sparse_categorical_accuracy: 0.4658 - val_loss: 4.5416 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 154/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0261 - sparse_categorical_accuracy: 0.4699 - val_loss: 4.4040 - val_sparse_categorical_accuracy: 0.4527\n",
      "Epoch 155/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.9175 - sparse_categorical_accuracy: 0.4647 - val_loss: 4.4689 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 156/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.9813 - sparse_categorical_accuracy: 0.4807 - val_loss: 4.5168 - val_sparse_categorical_accuracy: 0.4362\n",
      "Epoch 157/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0752 - sparse_categorical_accuracy: 0.4792 - val_loss: 4.5609 - val_sparse_categorical_accuracy: 0.4342\n",
      "Epoch 158/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.2537 - sparse_categorical_accuracy: 0.4761 - val_loss: 4.4821 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 159/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.9907 - sparse_categorical_accuracy: 0.4663 - val_loss: 4.4695 - val_sparse_categorical_accuracy: 0.4424\n",
      "Epoch 160/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8936 - sparse_categorical_accuracy: 0.4632 - val_loss: 4.4413 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 161/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8636 - sparse_categorical_accuracy: 0.4668 - val_loss: 4.4602 - val_sparse_categorical_accuracy: 0.4342\n",
      "Epoch 162/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8644 - sparse_categorical_accuracy: 0.4766 - val_loss: 4.5212 - val_sparse_categorical_accuracy: 0.4259\n",
      "Epoch 163/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.1782 - sparse_categorical_accuracy: 0.4545 - val_loss: 4.4648 - val_sparse_categorical_accuracy: 0.4342\n",
      "Epoch 164/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.8856 - sparse_categorical_accuracy: 0.4730 - val_loss: 4.4154 - val_sparse_categorical_accuracy: 0.4815\n",
      "Epoch 165/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.1209 - sparse_categorical_accuracy: 0.4740 - val_loss: 4.4209 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 166/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8451 - sparse_categorical_accuracy: 0.4807 - val_loss: 4.3914 - val_sparse_categorical_accuracy: 0.4650\n",
      "Epoch 167/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8808 - sparse_categorical_accuracy: 0.4653 - val_loss: 4.3908 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 168/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.9328 - sparse_categorical_accuracy: 0.4797 - val_loss: 4.3301 - val_sparse_categorical_accuracy: 0.4506\n",
      "Epoch 169/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.9564 - sparse_categorical_accuracy: 0.4647 - val_loss: 4.3413 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 170/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8561 - sparse_categorical_accuracy: 0.4833 - val_loss: 4.2356 - val_sparse_categorical_accuracy: 0.4568\n",
      "Epoch 171/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7695 - sparse_categorical_accuracy: 0.4843 - val_loss: 4.2772 - val_sparse_categorical_accuracy: 0.4630\n",
      "Epoch 172/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7762 - sparse_categorical_accuracy: 0.5116 - val_loss: 4.2159 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 173/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8003 - sparse_categorical_accuracy: 0.4884 - val_loss: 4.2866 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 174/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7725 - sparse_categorical_accuracy: 0.4972 - val_loss: 4.4314 - val_sparse_categorical_accuracy: 0.4300\n",
      "Epoch 175/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.0238 - sparse_categorical_accuracy: 0.4843 - val_loss: 4.3020 - val_sparse_categorical_accuracy: 0.4527\n",
      "Epoch 176/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8100 - sparse_categorical_accuracy: 0.4807 - val_loss: 4.3036 - val_sparse_categorical_accuracy: 0.4506\n",
      "Epoch 177/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7845 - sparse_categorical_accuracy: 0.4920 - val_loss: 4.2301 - val_sparse_categorical_accuracy: 0.4650\n",
      "Epoch 178/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8891 - sparse_categorical_accuracy: 0.4689 - val_loss: 4.3755 - val_sparse_categorical_accuracy: 0.4527\n",
      "Epoch 179/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8511 - sparse_categorical_accuracy: 0.4771 - val_loss: 4.2417 - val_sparse_categorical_accuracy: 0.4527\n",
      "Epoch 180/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.9026 - sparse_categorical_accuracy: 0.4720 - val_loss: 4.2351 - val_sparse_categorical_accuracy: 0.4506\n",
      "Epoch 181/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8501 - sparse_categorical_accuracy: 0.4735 - val_loss: 4.1653 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 182/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8133 - sparse_categorical_accuracy: 0.4900 - val_loss: 4.1303 - val_sparse_categorical_accuracy: 0.4568\n",
      "Epoch 183/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8981 - sparse_categorical_accuracy: 0.4812 - val_loss: 4.2672 - val_sparse_categorical_accuracy: 0.4671\n",
      "Epoch 184/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8797 - sparse_categorical_accuracy: 0.4874 - val_loss: 4.2406 - val_sparse_categorical_accuracy: 0.4362\n",
      "Epoch 185/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7717 - sparse_categorical_accuracy: 0.4864 - val_loss: 4.1821 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 186/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.8422 - sparse_categorical_accuracy: 0.4781 - val_loss: 4.1512 - val_sparse_categorical_accuracy: 0.4835\n",
      "Epoch 187/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7445 - sparse_categorical_accuracy: 0.4972 - val_loss: 4.2239 - val_sparse_categorical_accuracy: 0.4527\n",
      "Epoch 188/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.6430 - sparse_categorical_accuracy: 0.4961 - val_loss: 4.2176 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 189/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7804 - sparse_categorical_accuracy: 0.4910 - val_loss: 4.1407 - val_sparse_categorical_accuracy: 0.4588\n",
      "Epoch 190/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.9508 - sparse_categorical_accuracy: 0.5023 - val_loss: 4.1055 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 191/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.7411 - sparse_categorical_accuracy: 0.4894 - val_loss: 4.0864 - val_sparse_categorical_accuracy: 0.4568\n",
      "Epoch 192/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7570 - sparse_categorical_accuracy: 0.4972 - val_loss: 3.9928 - val_sparse_categorical_accuracy: 0.4794\n",
      "Epoch 193/3000\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.7129 - sparse_categorical_accuracy: 0.4889 - val_loss: 3.9529 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 194/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7138 - sparse_categorical_accuracy: 0.5018 - val_loss: 4.0352 - val_sparse_categorical_accuracy: 0.4547\n",
      "Epoch 195/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6801 - sparse_categorical_accuracy: 0.5172 - val_loss: 4.0331 - val_sparse_categorical_accuracy: 0.4527\n",
      "Epoch 196/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6797 - sparse_categorical_accuracy: 0.5126 - val_loss: 4.0373 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 197/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7543 - sparse_categorical_accuracy: 0.4869 - val_loss: 4.0007 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 198/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6427 - sparse_categorical_accuracy: 0.5023 - val_loss: 3.8899 - val_sparse_categorical_accuracy: 0.4753\n",
      "Epoch 199/3000\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.7864 - sparse_categorical_accuracy: 0.5095 - val_loss: 3.9474 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 200/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6770 - sparse_categorical_accuracy: 0.5039 - val_loss: 4.0132 - val_sparse_categorical_accuracy: 0.4733\n",
      "Epoch 201/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6468 - sparse_categorical_accuracy: 0.4977 - val_loss: 3.9110 - val_sparse_categorical_accuracy: 0.4609\n",
      "Epoch 202/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7769 - sparse_categorical_accuracy: 0.5033 - val_loss: 4.0762 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 203/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6974 - sparse_categorical_accuracy: 0.4915 - val_loss: 4.1491 - val_sparse_categorical_accuracy: 0.4383\n",
      "Epoch 204/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7016 - sparse_categorical_accuracy: 0.5003 - val_loss: 4.0599 - val_sparse_categorical_accuracy: 0.4897\n",
      "Epoch 205/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.7556 - sparse_categorical_accuracy: 0.5147 - val_loss: 4.0362 - val_sparse_categorical_accuracy: 0.4733\n",
      "Epoch 206/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6136 - sparse_categorical_accuracy: 0.5064 - val_loss: 3.9934 - val_sparse_categorical_accuracy: 0.4630\n",
      "Epoch 207/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6550 - sparse_categorical_accuracy: 0.5152 - val_loss: 4.0165 - val_sparse_categorical_accuracy: 0.4650\n",
      "Epoch 208/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6936 - sparse_categorical_accuracy: 0.4967 - val_loss: 4.1493 - val_sparse_categorical_accuracy: 0.4588\n",
      "Epoch 209/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6447 - sparse_categorical_accuracy: 0.5008 - val_loss: 4.2333 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 210/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.6914 - sparse_categorical_accuracy: 0.4987 - val_loss: 4.1934 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 211/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6067 - sparse_categorical_accuracy: 0.5023 - val_loss: 4.1481 - val_sparse_categorical_accuracy: 0.4650\n",
      "Epoch 212/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6168 - sparse_categorical_accuracy: 0.5090 - val_loss: 4.1322 - val_sparse_categorical_accuracy: 0.4815\n",
      "Epoch 213/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5956 - sparse_categorical_accuracy: 0.5193 - val_loss: 4.0669 - val_sparse_categorical_accuracy: 0.4568\n",
      "Epoch 214/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5423 - sparse_categorical_accuracy: 0.5291 - val_loss: 4.0422 - val_sparse_categorical_accuracy: 0.4630\n",
      "Epoch 215/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5366 - sparse_categorical_accuracy: 0.5265 - val_loss: 3.9933 - val_sparse_categorical_accuracy: 0.4630\n",
      "Epoch 216/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6035 - sparse_categorical_accuracy: 0.5157 - val_loss: 3.9099 - val_sparse_categorical_accuracy: 0.4897\n",
      "Epoch 217/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5935 - sparse_categorical_accuracy: 0.5265 - val_loss: 3.9338 - val_sparse_categorical_accuracy: 0.4753\n",
      "Epoch 218/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6485 - sparse_categorical_accuracy: 0.5116 - val_loss: 4.0624 - val_sparse_categorical_accuracy: 0.4609\n",
      "Epoch 219/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6255 - sparse_categorical_accuracy: 0.5147 - val_loss: 4.0725 - val_sparse_categorical_accuracy: 0.4342\n",
      "Epoch 220/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6154 - sparse_categorical_accuracy: 0.5188 - val_loss: 3.9097 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 221/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.5749 - sparse_categorical_accuracy: 0.5183 - val_loss: 3.7772 - val_sparse_categorical_accuracy: 0.5021\n",
      "Epoch 222/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5905 - sparse_categorical_accuracy: 0.5178 - val_loss: 3.7147 - val_sparse_categorical_accuracy: 0.4774\n",
      "Epoch 223/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5595 - sparse_categorical_accuracy: 0.5291 - val_loss: 3.8345 - val_sparse_categorical_accuracy: 0.4588\n",
      "Epoch 224/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5547 - sparse_categorical_accuracy: 0.5353 - val_loss: 3.9173 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 225/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6982 - sparse_categorical_accuracy: 0.5111 - val_loss: 3.9023 - val_sparse_categorical_accuracy: 0.4774\n",
      "Epoch 226/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5678 - sparse_categorical_accuracy: 0.5280 - val_loss: 4.0286 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 227/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5355 - sparse_categorical_accuracy: 0.5296 - val_loss: 4.0489 - val_sparse_categorical_accuracy: 0.4588\n",
      "Epoch 228/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5208 - sparse_categorical_accuracy: 0.5136 - val_loss: 3.9386 - val_sparse_categorical_accuracy: 0.4856\n",
      "Epoch 229/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5687 - sparse_categorical_accuracy: 0.5425 - val_loss: 3.9195 - val_sparse_categorical_accuracy: 0.4753\n",
      "Epoch 230/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5555 - sparse_categorical_accuracy: 0.5337 - val_loss: 3.9645 - val_sparse_categorical_accuracy: 0.4671\n",
      "Epoch 231/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 1.5258 - sparse_categorical_accuracy: 0.5394 - val_loss: 3.8969 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 232/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5952 - sparse_categorical_accuracy: 0.5244 - val_loss: 3.8078 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 233/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.6249 - sparse_categorical_accuracy: 0.5301 - val_loss: 3.9590 - val_sparse_categorical_accuracy: 0.4588\n",
      "Epoch 234/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5709 - sparse_categorical_accuracy: 0.5152 - val_loss: 4.2862 - val_sparse_categorical_accuracy: 0.4383\n",
      "Epoch 235/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5913 - sparse_categorical_accuracy: 0.5033 - val_loss: 4.1441 - val_sparse_categorical_accuracy: 0.5041\n",
      "Epoch 236/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5081 - sparse_categorical_accuracy: 0.5275 - val_loss: 4.0911 - val_sparse_categorical_accuracy: 0.4815\n",
      "Epoch 237/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5032 - sparse_categorical_accuracy: 0.5455 - val_loss: 4.0644 - val_sparse_categorical_accuracy: 0.4774\n",
      "Epoch 238/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5613 - sparse_categorical_accuracy: 0.5368 - val_loss: 3.9327 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 239/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4586 - sparse_categorical_accuracy: 0.5425 - val_loss: 3.9158 - val_sparse_categorical_accuracy: 0.5062\n",
      "Epoch 240/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5920 - sparse_categorical_accuracy: 0.5368 - val_loss: 3.8347 - val_sparse_categorical_accuracy: 0.4568\n",
      "Epoch 241/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5100 - sparse_categorical_accuracy: 0.5322 - val_loss: 3.9096 - val_sparse_categorical_accuracy: 0.4465\n",
      "Epoch 242/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.5706 - sparse_categorical_accuracy: 0.5178 - val_loss: 3.7792 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 243/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5116 - sparse_categorical_accuracy: 0.5301 - val_loss: 3.8169 - val_sparse_categorical_accuracy: 0.5041\n",
      "Epoch 244/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4499 - sparse_categorical_accuracy: 0.5378 - val_loss: 3.8822 - val_sparse_categorical_accuracy: 0.4815\n",
      "Epoch 245/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5146 - sparse_categorical_accuracy: 0.5435 - val_loss: 3.8661 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 246/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4607 - sparse_categorical_accuracy: 0.5507 - val_loss: 3.8535 - val_sparse_categorical_accuracy: 0.4671\n",
      "Epoch 247/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4778 - sparse_categorical_accuracy: 0.5337 - val_loss: 3.7736 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 248/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4694 - sparse_categorical_accuracy: 0.5275 - val_loss: 4.0295 - val_sparse_categorical_accuracy: 0.4403\n",
      "Epoch 249/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.6404 - sparse_categorical_accuracy: 0.5095 - val_loss: 3.8091 - val_sparse_categorical_accuracy: 0.5082\n",
      "Epoch 250/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4849 - sparse_categorical_accuracy: 0.5337 - val_loss: 3.8019 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 251/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4521 - sparse_categorical_accuracy: 0.5425 - val_loss: 3.8308 - val_sparse_categorical_accuracy: 0.4712\n",
      "Epoch 252/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4689 - sparse_categorical_accuracy: 0.5383 - val_loss: 3.8451 - val_sparse_categorical_accuracy: 0.4856\n",
      "Epoch 253/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5342 - sparse_categorical_accuracy: 0.5476 - val_loss: 3.8128 - val_sparse_categorical_accuracy: 0.4856\n",
      "Epoch 254/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4065 - sparse_categorical_accuracy: 0.5548 - val_loss: 3.7357 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 255/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4221 - sparse_categorical_accuracy: 0.5481 - val_loss: 3.7045 - val_sparse_categorical_accuracy: 0.5185\n",
      "Epoch 256/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4544 - sparse_categorical_accuracy: 0.5481 - val_loss: 3.8634 - val_sparse_categorical_accuracy: 0.4588\n",
      "Epoch 257/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.5996 - sparse_categorical_accuracy: 0.5471 - val_loss: 3.8234 - val_sparse_categorical_accuracy: 0.4979\n",
      "Epoch 258/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5150 - sparse_categorical_accuracy: 0.5378 - val_loss: 3.9328 - val_sparse_categorical_accuracy: 0.5021\n",
      "Epoch 259/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4368 - sparse_categorical_accuracy: 0.5455 - val_loss: 4.0256 - val_sparse_categorical_accuracy: 0.4650\n",
      "Epoch 260/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4498 - sparse_categorical_accuracy: 0.5502 - val_loss: 3.8228 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 261/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4497 - sparse_categorical_accuracy: 0.5522 - val_loss: 3.8012 - val_sparse_categorical_accuracy: 0.4877\n",
      "Epoch 262/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4548 - sparse_categorical_accuracy: 0.5430 - val_loss: 3.7513 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 263/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4201 - sparse_categorical_accuracy: 0.5466 - val_loss: 3.7628 - val_sparse_categorical_accuracy: 0.4979\n",
      "Epoch 264/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5306 - sparse_categorical_accuracy: 0.5517 - val_loss: 3.7495 - val_sparse_categorical_accuracy: 0.4794\n",
      "Epoch 265/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4009 - sparse_categorical_accuracy: 0.5543 - val_loss: 3.8242 - val_sparse_categorical_accuracy: 0.4774\n",
      "Epoch 266/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4471 - sparse_categorical_accuracy: 0.5466 - val_loss: 3.8552 - val_sparse_categorical_accuracy: 0.4877\n",
      "Epoch 267/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4140 - sparse_categorical_accuracy: 0.5641 - val_loss: 3.8728 - val_sparse_categorical_accuracy: 0.5082\n",
      "Epoch 268/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4661 - sparse_categorical_accuracy: 0.5502 - val_loss: 4.0003 - val_sparse_categorical_accuracy: 0.4733\n",
      "Epoch 269/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4367 - sparse_categorical_accuracy: 0.5528 - val_loss: 4.0176 - val_sparse_categorical_accuracy: 0.5062\n",
      "Epoch 270/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4939 - sparse_categorical_accuracy: 0.5492 - val_loss: 3.9782 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 271/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4023 - sparse_categorical_accuracy: 0.5445 - val_loss: 3.9510 - val_sparse_categorical_accuracy: 0.4753\n",
      "Epoch 272/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4669 - sparse_categorical_accuracy: 0.5409 - val_loss: 3.9246 - val_sparse_categorical_accuracy: 0.4527\n",
      "Epoch 273/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4864 - sparse_categorical_accuracy: 0.5455 - val_loss: 3.8238 - val_sparse_categorical_accuracy: 0.5103\n",
      "Epoch 274/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4193 - sparse_categorical_accuracy: 0.5512 - val_loss: 3.8381 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 275/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4164 - sparse_categorical_accuracy: 0.5548 - val_loss: 3.8516 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 276/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.3949 - sparse_categorical_accuracy: 0.5517 - val_loss: 3.8726 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 277/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.4161 - sparse_categorical_accuracy: 0.5610 - val_loss: 3.9275 - val_sparse_categorical_accuracy: 0.4753\n",
      "Epoch 278/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4527 - sparse_categorical_accuracy: 0.5497 - val_loss: 3.9471 - val_sparse_categorical_accuracy: 0.4444\n",
      "Epoch 279/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4710 - sparse_categorical_accuracy: 0.5280 - val_loss: 3.8317 - val_sparse_categorical_accuracy: 0.4774\n",
      "Epoch 280/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.3445 - sparse_categorical_accuracy: 0.5594 - val_loss: 3.7979 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 281/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.5468 - sparse_categorical_accuracy: 0.5481 - val_loss: 3.7354 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 282/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3584 - sparse_categorical_accuracy: 0.5666 - val_loss: 3.7039 - val_sparse_categorical_accuracy: 0.4794\n",
      "Epoch 283/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.4412 - sparse_categorical_accuracy: 0.5486 - val_loss: 3.9456 - val_sparse_categorical_accuracy: 0.4259\n",
      "Epoch 284/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4534 - sparse_categorical_accuracy: 0.5260 - val_loss: 3.6715 - val_sparse_categorical_accuracy: 0.5103\n",
      "Epoch 285/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4333 - sparse_categorical_accuracy: 0.5404 - val_loss: 3.6612 - val_sparse_categorical_accuracy: 0.4733\n",
      "Epoch 286/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4499 - sparse_categorical_accuracy: 0.5666 - val_loss: 3.6431 - val_sparse_categorical_accuracy: 0.5041\n",
      "Epoch 287/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3156 - sparse_categorical_accuracy: 0.5718 - val_loss: 3.7456 - val_sparse_categorical_accuracy: 0.4774\n",
      "Epoch 288/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3664 - sparse_categorical_accuracy: 0.5697 - val_loss: 3.7329 - val_sparse_categorical_accuracy: 0.4979\n",
      "Epoch 289/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3773 - sparse_categorical_accuracy: 0.5610 - val_loss: 3.7136 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 290/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3863 - sparse_categorical_accuracy: 0.5682 - val_loss: 3.7384 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 291/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3390 - sparse_categorical_accuracy: 0.5805 - val_loss: 3.7516 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 292/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3375 - sparse_categorical_accuracy: 0.5728 - val_loss: 3.8003 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 293/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3874 - sparse_categorical_accuracy: 0.5661 - val_loss: 3.7423 - val_sparse_categorical_accuracy: 0.4979\n",
      "Epoch 294/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3265 - sparse_categorical_accuracy: 0.5677 - val_loss: 3.7600 - val_sparse_categorical_accuracy: 0.4979\n",
      "Epoch 295/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3457 - sparse_categorical_accuracy: 0.5733 - val_loss: 3.7227 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 296/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3501 - sparse_categorical_accuracy: 0.5584 - val_loss: 3.7270 - val_sparse_categorical_accuracy: 0.5041\n",
      "Epoch 297/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4223 - sparse_categorical_accuracy: 0.5533 - val_loss: 3.7792 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 298/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3232 - sparse_categorical_accuracy: 0.5728 - val_loss: 3.6445 - val_sparse_categorical_accuracy: 0.5082\n",
      "Epoch 299/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3021 - sparse_categorical_accuracy: 0.5723 - val_loss: 3.6532 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 300/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2768 - sparse_categorical_accuracy: 0.5862 - val_loss: 3.6991 - val_sparse_categorical_accuracy: 0.5062\n",
      "Epoch 301/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2839 - sparse_categorical_accuracy: 0.5908 - val_loss: 3.6483 - val_sparse_categorical_accuracy: 0.5123\n",
      "Epoch 302/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3194 - sparse_categorical_accuracy: 0.5682 - val_loss: 3.6434 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 303/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3413 - sparse_categorical_accuracy: 0.5769 - val_loss: 3.7054 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 304/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.4217 - sparse_categorical_accuracy: 0.5718 - val_loss: 3.8500 - val_sparse_categorical_accuracy: 0.5082\n",
      "Epoch 305/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3841 - sparse_categorical_accuracy: 0.5579 - val_loss: 4.1907 - val_sparse_categorical_accuracy: 0.4568\n",
      "Epoch 306/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3346 - sparse_categorical_accuracy: 0.5548 - val_loss: 4.0445 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 307/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3168 - sparse_categorical_accuracy: 0.5826 - val_loss: 4.2046 - val_sparse_categorical_accuracy: 0.5185\n",
      "Epoch 308/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3424 - sparse_categorical_accuracy: 0.5857 - val_loss: 4.1956 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 309/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2736 - sparse_categorical_accuracy: 0.5816 - val_loss: 4.1975 - val_sparse_categorical_accuracy: 0.4815\n",
      "Epoch 310/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.3508 - sparse_categorical_accuracy: 0.5625 - val_loss: 4.1139 - val_sparse_categorical_accuracy: 0.5021\n",
      "Epoch 311/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3190 - sparse_categorical_accuracy: 0.5847 - val_loss: 3.9727 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 312/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.3542 - sparse_categorical_accuracy: 0.5713 - val_loss: 3.9784 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 313/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3284 - sparse_categorical_accuracy: 0.5790 - val_loss: 4.0190 - val_sparse_categorical_accuracy: 0.5041\n",
      "Epoch 314/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3670 - sparse_categorical_accuracy: 0.5703 - val_loss: 3.9671 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 315/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3402 - sparse_categorical_accuracy: 0.5805 - val_loss: 3.8451 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 316/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3151 - sparse_categorical_accuracy: 0.5697 - val_loss: 3.8448 - val_sparse_categorical_accuracy: 0.4733\n",
      "Epoch 317/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3293 - sparse_categorical_accuracy: 0.5816 - val_loss: 3.8038 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 318/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2652 - sparse_categorical_accuracy: 0.5847 - val_loss: 3.8448 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 319/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3448 - sparse_categorical_accuracy: 0.5790 - val_loss: 3.8619 - val_sparse_categorical_accuracy: 0.5041\n",
      "Epoch 320/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3390 - sparse_categorical_accuracy: 0.5692 - val_loss: 3.8980 - val_sparse_categorical_accuracy: 0.4794\n",
      "Epoch 321/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3067 - sparse_categorical_accuracy: 0.5749 - val_loss: 3.9183 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 322/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3375 - sparse_categorical_accuracy: 0.5888 - val_loss: 3.8442 - val_sparse_categorical_accuracy: 0.5021\n",
      "Epoch 323/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2818 - sparse_categorical_accuracy: 0.5826 - val_loss: 3.8730 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 324/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.2496 - sparse_categorical_accuracy: 0.5795 - val_loss: 3.7579 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 325/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2760 - sparse_categorical_accuracy: 0.5836 - val_loss: 3.8030 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 326/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.2813 - sparse_categorical_accuracy: 0.5816 - val_loss: 3.8252 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 327/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2410 - sparse_categorical_accuracy: 0.5950 - val_loss: 3.9156 - val_sparse_categorical_accuracy: 0.5021\n",
      "Epoch 328/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2668 - sparse_categorical_accuracy: 0.5826 - val_loss: 3.7584 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 329/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2556 - sparse_categorical_accuracy: 0.5780 - val_loss: 3.7845 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 330/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2483 - sparse_categorical_accuracy: 0.5831 - val_loss: 3.8151 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 331/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2755 - sparse_categorical_accuracy: 0.5841 - val_loss: 3.9268 - val_sparse_categorical_accuracy: 0.5123\n",
      "Epoch 332/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2700 - sparse_categorical_accuracy: 0.5852 - val_loss: 3.8699 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 333/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.2701 - sparse_categorical_accuracy: 0.5728 - val_loss: 3.8000 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 334/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2735 - sparse_categorical_accuracy: 0.5903 - val_loss: 3.8974 - val_sparse_categorical_accuracy: 0.5021\n",
      "Epoch 335/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2822 - sparse_categorical_accuracy: 0.5960 - val_loss: 3.9215 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 336/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2407 - sparse_categorical_accuracy: 0.5965 - val_loss: 4.0034 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 337/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2864 - sparse_categorical_accuracy: 0.5955 - val_loss: 3.8401 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 338/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2847 - sparse_categorical_accuracy: 0.5852 - val_loss: 3.8365 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 339/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2267 - sparse_categorical_accuracy: 0.5970 - val_loss: 3.8620 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 340/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2374 - sparse_categorical_accuracy: 0.5857 - val_loss: 3.9267 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 341/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.2953 - sparse_categorical_accuracy: 0.5960 - val_loss: 4.0703 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 342/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3144 - sparse_categorical_accuracy: 0.5656 - val_loss: 3.9984 - val_sparse_categorical_accuracy: 0.5123\n",
      "Epoch 343/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2491 - sparse_categorical_accuracy: 0.5893 - val_loss: 4.0215 - val_sparse_categorical_accuracy: 0.4897\n",
      "Epoch 344/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.2200 - sparse_categorical_accuracy: 0.6058 - val_loss: 3.8481 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 345/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2598 - sparse_categorical_accuracy: 0.5960 - val_loss: 3.9306 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 346/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2223 - sparse_categorical_accuracy: 0.6016 - val_loss: 4.1135 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 347/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.3108 - sparse_categorical_accuracy: 0.5893 - val_loss: 4.0723 - val_sparse_categorical_accuracy: 0.4691\n",
      "Epoch 348/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2817 - sparse_categorical_accuracy: 0.5867 - val_loss: 4.0445 - val_sparse_categorical_accuracy: 0.4897\n",
      "Epoch 349/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2556 - sparse_categorical_accuracy: 0.5908 - val_loss: 3.9004 - val_sparse_categorical_accuracy: 0.4979\n",
      "Epoch 350/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2418 - sparse_categorical_accuracy: 0.5939 - val_loss: 3.9595 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 351/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2269 - sparse_categorical_accuracy: 0.5872 - val_loss: 3.8847 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 352/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2026 - sparse_categorical_accuracy: 0.6047 - val_loss: 3.9526 - val_sparse_categorical_accuracy: 0.5185\n",
      "Epoch 353/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2279 - sparse_categorical_accuracy: 0.5991 - val_loss: 3.9057 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 354/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2524 - sparse_categorical_accuracy: 0.5986 - val_loss: 3.7820 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 355/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1721 - sparse_categorical_accuracy: 0.6135 - val_loss: 3.9979 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 356/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.2604 - sparse_categorical_accuracy: 0.5939 - val_loss: 3.7646 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 357/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2568 - sparse_categorical_accuracy: 0.6011 - val_loss: 3.7136 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 358/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1997 - sparse_categorical_accuracy: 0.6109 - val_loss: 3.7157 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 359/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1924 - sparse_categorical_accuracy: 0.6001 - val_loss: 3.7678 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 360/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.2061 - sparse_categorical_accuracy: 0.5919 - val_loss: 3.8976 - val_sparse_categorical_accuracy: 0.4835\n",
      "Epoch 361/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2665 - sparse_categorical_accuracy: 0.5872 - val_loss: 3.8204 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 362/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1978 - sparse_categorical_accuracy: 0.5970 - val_loss: 3.7468 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 363/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1982 - sparse_categorical_accuracy: 0.6001 - val_loss: 3.7036 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 364/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2099 - sparse_categorical_accuracy: 0.6104 - val_loss: 3.7762 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 365/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.1759 - sparse_categorical_accuracy: 0.6197 - val_loss: 3.8198 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 366/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.1799 - sparse_categorical_accuracy: 0.6181 - val_loss: 3.8217 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 367/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2882 - sparse_categorical_accuracy: 0.5862 - val_loss: 4.0215 - val_sparse_categorical_accuracy: 0.4897\n",
      "Epoch 368/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2049 - sparse_categorical_accuracy: 0.5939 - val_loss: 3.9523 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 369/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2222 - sparse_categorical_accuracy: 0.5965 - val_loss: 3.8190 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 370/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2296 - sparse_categorical_accuracy: 0.5975 - val_loss: 3.7763 - val_sparse_categorical_accuracy: 0.5103\n",
      "Epoch 371/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.2121 - sparse_categorical_accuracy: 0.5934 - val_loss: 3.7391 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 372/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1845 - sparse_categorical_accuracy: 0.6073 - val_loss: 3.8389 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 373/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1819 - sparse_categorical_accuracy: 0.6047 - val_loss: 3.8904 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 374/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1881 - sparse_categorical_accuracy: 0.6063 - val_loss: 3.8937 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 375/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1833 - sparse_categorical_accuracy: 0.6145 - val_loss: 3.9394 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 376/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1660 - sparse_categorical_accuracy: 0.6181 - val_loss: 3.8804 - val_sparse_categorical_accuracy: 0.5082\n",
      "Epoch 377/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1814 - sparse_categorical_accuracy: 0.6119 - val_loss: 3.9620 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 378/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1856 - sparse_categorical_accuracy: 0.6119 - val_loss: 3.8625 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 379/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2041 - sparse_categorical_accuracy: 0.6186 - val_loss: 3.8325 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 380/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2458 - sparse_categorical_accuracy: 0.6099 - val_loss: 3.8737 - val_sparse_categorical_accuracy: 0.5123\n",
      "Epoch 381/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1980 - sparse_categorical_accuracy: 0.6001 - val_loss: 4.1353 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 382/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1953 - sparse_categorical_accuracy: 0.5970 - val_loss: 3.8573 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 383/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2055 - sparse_categorical_accuracy: 0.6150 - val_loss: 3.8780 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 384/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2257 - sparse_categorical_accuracy: 0.6058 - val_loss: 3.7900 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 385/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1369 - sparse_categorical_accuracy: 0.6207 - val_loss: 3.8674 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 386/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1618 - sparse_categorical_accuracy: 0.6104 - val_loss: 3.9140 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 387/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2063 - sparse_categorical_accuracy: 0.6027 - val_loss: 3.8442 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 388/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2067 - sparse_categorical_accuracy: 0.5919 - val_loss: 4.1093 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 389/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2424 - sparse_categorical_accuracy: 0.5960 - val_loss: 3.7842 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 390/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1661 - sparse_categorical_accuracy: 0.6083 - val_loss: 3.9092 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 391/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.1715 - sparse_categorical_accuracy: 0.6181 - val_loss: 3.8279 - val_sparse_categorical_accuracy: 0.5473\n",
      "Epoch 392/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1503 - sparse_categorical_accuracy: 0.6197 - val_loss: 3.7762 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 393/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1700 - sparse_categorical_accuracy: 0.6047 - val_loss: 3.6531 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 394/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1294 - sparse_categorical_accuracy: 0.6253 - val_loss: 3.7537 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 395/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.1418 - sparse_categorical_accuracy: 0.6125 - val_loss: 3.7159 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 396/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.1071 - sparse_categorical_accuracy: 0.6274 - val_loss: 3.6964 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 397/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1682 - sparse_categorical_accuracy: 0.6207 - val_loss: 3.7383 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 398/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.1339 - sparse_categorical_accuracy: 0.6197 - val_loss: 3.7388 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 399/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1501 - sparse_categorical_accuracy: 0.6145 - val_loss: 3.6862 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 400/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1351 - sparse_categorical_accuracy: 0.6222 - val_loss: 3.7114 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 401/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.2090 - sparse_categorical_accuracy: 0.6233 - val_loss: 3.8544 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 402/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1979 - sparse_categorical_accuracy: 0.6186 - val_loss: 3.7820 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 403/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1617 - sparse_categorical_accuracy: 0.6325 - val_loss: 3.8110 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 404/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1147 - sparse_categorical_accuracy: 0.6222 - val_loss: 3.7997 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 405/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1692 - sparse_categorical_accuracy: 0.6207 - val_loss: 3.8767 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 406/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1419 - sparse_categorical_accuracy: 0.6191 - val_loss: 3.8360 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 407/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0866 - sparse_categorical_accuracy: 0.6341 - val_loss: 3.8673 - val_sparse_categorical_accuracy: 0.5185\n",
      "Epoch 408/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1166 - sparse_categorical_accuracy: 0.6227 - val_loss: 3.8383 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 409/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1279 - sparse_categorical_accuracy: 0.6197 - val_loss: 3.9317 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 410/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1374 - sparse_categorical_accuracy: 0.6222 - val_loss: 3.8372 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 411/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1610 - sparse_categorical_accuracy: 0.6161 - val_loss: 3.8590 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 412/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1268 - sparse_categorical_accuracy: 0.6161 - val_loss: 3.7002 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 413/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.2345 - sparse_categorical_accuracy: 0.5898 - val_loss: 3.7809 - val_sparse_categorical_accuracy: 0.5082\n",
      "Epoch 414/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1452 - sparse_categorical_accuracy: 0.6222 - val_loss: 3.8434 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 415/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1489 - sparse_categorical_accuracy: 0.6207 - val_loss: 3.9171 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 416/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1301 - sparse_categorical_accuracy: 0.6186 - val_loss: 3.7384 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 417/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1326 - sparse_categorical_accuracy: 0.6238 - val_loss: 3.7360 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 418/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0916 - sparse_categorical_accuracy: 0.6305 - val_loss: 3.8106 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 419/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.2071 - sparse_categorical_accuracy: 0.6284 - val_loss: 3.8088 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 420/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1575 - sparse_categorical_accuracy: 0.6320 - val_loss: 3.8533 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 421/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0977 - sparse_categorical_accuracy: 0.6233 - val_loss: 3.9345 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 422/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1296 - sparse_categorical_accuracy: 0.6284 - val_loss: 4.0267 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 423/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1661 - sparse_categorical_accuracy: 0.6104 - val_loss: 3.9979 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 424/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1333 - sparse_categorical_accuracy: 0.6191 - val_loss: 3.9943 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 425/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1213 - sparse_categorical_accuracy: 0.6258 - val_loss: 3.9700 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 426/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0877 - sparse_categorical_accuracy: 0.6475 - val_loss: 3.9077 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 427/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0846 - sparse_categorical_accuracy: 0.6423 - val_loss: 3.8965 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 428/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1245 - sparse_categorical_accuracy: 0.6377 - val_loss: 3.9083 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 429/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1338 - sparse_categorical_accuracy: 0.6197 - val_loss: 4.0699 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 430/3000\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.1221 - sparse_categorical_accuracy: 0.6315 - val_loss: 4.0522 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 431/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0493 - sparse_categorical_accuracy: 0.6444 - val_loss: 4.0579 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 432/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0704 - sparse_categorical_accuracy: 0.6392 - val_loss: 4.0273 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 433/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1008 - sparse_categorical_accuracy: 0.6284 - val_loss: 3.9664 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 434/3000\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 1.1676 - sparse_categorical_accuracy: 0.6222 - val_loss: 4.0417 - val_sparse_categorical_accuracy: 0.5556\n",
      "Epoch 435/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1294 - sparse_categorical_accuracy: 0.6315 - val_loss: 3.9880 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 436/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1221 - sparse_categorical_accuracy: 0.6315 - val_loss: 3.9202 - val_sparse_categorical_accuracy: 0.5473\n",
      "Epoch 437/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0909 - sparse_categorical_accuracy: 0.6356 - val_loss: 3.9030 - val_sparse_categorical_accuracy: 0.5494\n",
      "Epoch 438/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0991 - sparse_categorical_accuracy: 0.6366 - val_loss: 3.9343 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 439/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0648 - sparse_categorical_accuracy: 0.6449 - val_loss: 3.9511 - val_sparse_categorical_accuracy: 0.5082\n",
      "Epoch 440/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1348 - sparse_categorical_accuracy: 0.6253 - val_loss: 3.8160 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 441/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0669 - sparse_categorical_accuracy: 0.6336 - val_loss: 3.8833 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 442/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0576 - sparse_categorical_accuracy: 0.6382 - val_loss: 3.9790 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 443/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1060 - sparse_categorical_accuracy: 0.6310 - val_loss: 4.0241 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 444/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0415 - sparse_categorical_accuracy: 0.6428 - val_loss: 4.0053 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 445/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0543 - sparse_categorical_accuracy: 0.6567 - val_loss: 3.9728 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 446/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0451 - sparse_categorical_accuracy: 0.6480 - val_loss: 4.1552 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 447/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1062 - sparse_categorical_accuracy: 0.6372 - val_loss: 4.0344 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 448/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1540 - sparse_categorical_accuracy: 0.6366 - val_loss: 4.0084 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 449/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0881 - sparse_categorical_accuracy: 0.6418 - val_loss: 3.9357 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 450/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1102 - sparse_categorical_accuracy: 0.6346 - val_loss: 3.9533 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 451/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0864 - sparse_categorical_accuracy: 0.6372 - val_loss: 3.9837 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 452/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1029 - sparse_categorical_accuracy: 0.6356 - val_loss: 3.9590 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 453/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0773 - sparse_categorical_accuracy: 0.6402 - val_loss: 3.9512 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 454/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0764 - sparse_categorical_accuracy: 0.6372 - val_loss: 3.8099 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 455/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0402 - sparse_categorical_accuracy: 0.6547 - val_loss: 3.7762 - val_sparse_categorical_accuracy: 0.5494\n",
      "Epoch 456/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1047 - sparse_categorical_accuracy: 0.6351 - val_loss: 3.8678 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 457/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.0775 - sparse_categorical_accuracy: 0.6402 - val_loss: 3.7823 - val_sparse_categorical_accuracy: 0.5556\n",
      "Epoch 458/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0303 - sparse_categorical_accuracy: 0.6562 - val_loss: 3.8456 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 459/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0441 - sparse_categorical_accuracy: 0.6438 - val_loss: 3.8360 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 460/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0460 - sparse_categorical_accuracy: 0.6495 - val_loss: 3.9018 - val_sparse_categorical_accuracy: 0.5185\n",
      "Epoch 461/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0915 - sparse_categorical_accuracy: 0.6464 - val_loss: 3.8892 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 462/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0770 - sparse_categorical_accuracy: 0.6341 - val_loss: 3.8288 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 463/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0695 - sparse_categorical_accuracy: 0.6438 - val_loss: 3.8672 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 464/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0502 - sparse_categorical_accuracy: 0.6444 - val_loss: 3.8100 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 465/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1088 - sparse_categorical_accuracy: 0.6418 - val_loss: 3.9317 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 466/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1061 - sparse_categorical_accuracy: 0.6361 - val_loss: 3.8534 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 467/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0820 - sparse_categorical_accuracy: 0.6423 - val_loss: 3.5873 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 468/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0592 - sparse_categorical_accuracy: 0.6624 - val_loss: 3.5477 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 469/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0332 - sparse_categorical_accuracy: 0.6485 - val_loss: 3.7559 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 470/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0299 - sparse_categorical_accuracy: 0.6577 - val_loss: 3.8167 - val_sparse_categorical_accuracy: 0.5494\n",
      "Epoch 471/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.0450 - sparse_categorical_accuracy: 0.6541 - val_loss: 3.9056 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 472/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0719 - sparse_categorical_accuracy: 0.6402 - val_loss: 3.8047 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 473/3000\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.0364 - sparse_categorical_accuracy: 0.6531 - val_loss: 3.6992 - val_sparse_categorical_accuracy: 0.5638\n",
      "Epoch 474/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0638 - sparse_categorical_accuracy: 0.6495 - val_loss: 3.7382 - val_sparse_categorical_accuracy: 0.5494\n",
      "Epoch 475/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0621 - sparse_categorical_accuracy: 0.6372 - val_loss: 3.8278 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 476/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0705 - sparse_categorical_accuracy: 0.6505 - val_loss: 3.8238 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 477/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0365 - sparse_categorical_accuracy: 0.6531 - val_loss: 3.6664 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 478/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0309 - sparse_categorical_accuracy: 0.6541 - val_loss: 3.8559 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 479/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0374 - sparse_categorical_accuracy: 0.6480 - val_loss: 3.8864 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 480/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0254 - sparse_categorical_accuracy: 0.6598 - val_loss: 3.9305 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 481/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0007 - sparse_categorical_accuracy: 0.6716 - val_loss: 3.9847 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 482/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0513 - sparse_categorical_accuracy: 0.6500 - val_loss: 3.9842 - val_sparse_categorical_accuracy: 0.5494\n",
      "Epoch 483/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0302 - sparse_categorical_accuracy: 0.6500 - val_loss: 4.0085 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 484/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0364 - sparse_categorical_accuracy: 0.6511 - val_loss: 4.0198 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 485/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0383 - sparse_categorical_accuracy: 0.6567 - val_loss: 3.9265 - val_sparse_categorical_accuracy: 0.5638\n",
      "Epoch 486/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.1404 - sparse_categorical_accuracy: 0.6577 - val_loss: 3.6704 - val_sparse_categorical_accuracy: 0.5576\n",
      "Epoch 487/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0149 - sparse_categorical_accuracy: 0.6624 - val_loss: 3.5978 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 488/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0417 - sparse_categorical_accuracy: 0.6526 - val_loss: 3.7268 - val_sparse_categorical_accuracy: 0.5576\n",
      "Epoch 489/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0031 - sparse_categorical_accuracy: 0.6583 - val_loss: 3.9111 - val_sparse_categorical_accuracy: 0.5597\n",
      "Epoch 490/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0482 - sparse_categorical_accuracy: 0.6531 - val_loss: 3.7874 - val_sparse_categorical_accuracy: 0.5617\n",
      "Epoch 491/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0087 - sparse_categorical_accuracy: 0.6670 - val_loss: 3.8216 - val_sparse_categorical_accuracy: 0.5617\n",
      "Epoch 492/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0131 - sparse_categorical_accuracy: 0.6706 - val_loss: 3.9945 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 493/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0325 - sparse_categorical_accuracy: 0.6557 - val_loss: 3.9703 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 494/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0264 - sparse_categorical_accuracy: 0.6608 - val_loss: 3.9180 - val_sparse_categorical_accuracy: 0.5473\n",
      "Epoch 495/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0116 - sparse_categorical_accuracy: 0.6644 - val_loss: 3.9315 - val_sparse_categorical_accuracy: 0.5597\n",
      "Epoch 496/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0475 - sparse_categorical_accuracy: 0.6639 - val_loss: 3.9552 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 497/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.1427 - sparse_categorical_accuracy: 0.6531 - val_loss: 3.9678 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 498/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0193 - sparse_categorical_accuracy: 0.6660 - val_loss: 4.1251 - val_sparse_categorical_accuracy: 0.5473\n",
      "Epoch 499/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0121 - sparse_categorical_accuracy: 0.6608 - val_loss: 4.0651 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 500/3000\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.0057 - sparse_categorical_accuracy: 0.6650 - val_loss: 4.1331 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 501/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9980 - sparse_categorical_accuracy: 0.6680 - val_loss: 3.9769 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 502/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0220 - sparse_categorical_accuracy: 0.6495 - val_loss: 3.8964 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 503/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9935 - sparse_categorical_accuracy: 0.6675 - val_loss: 3.9036 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 504/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9770 - sparse_categorical_accuracy: 0.6639 - val_loss: 3.9996 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 505/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0331 - sparse_categorical_accuracy: 0.6598 - val_loss: 4.0972 - val_sparse_categorical_accuracy: 0.5185\n",
      "Epoch 506/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0498 - sparse_categorical_accuracy: 0.6464 - val_loss: 3.9014 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 507/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9936 - sparse_categorical_accuracy: 0.6660 - val_loss: 3.8383 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 508/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0270 - sparse_categorical_accuracy: 0.6619 - val_loss: 3.9022 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 509/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0306 - sparse_categorical_accuracy: 0.6536 - val_loss: 3.8721 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 510/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9931 - sparse_categorical_accuracy: 0.6644 - val_loss: 3.9372 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 511/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.0068 - sparse_categorical_accuracy: 0.6557 - val_loss: 3.8902 - val_sparse_categorical_accuracy: 0.5494\n",
      "Epoch 512/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9776 - sparse_categorical_accuracy: 0.6706 - val_loss: 3.8794 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 513/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.0221 - sparse_categorical_accuracy: 0.6691 - val_loss: 3.9923 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 514/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9875 - sparse_categorical_accuracy: 0.6588 - val_loss: 4.0571 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 515/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9889 - sparse_categorical_accuracy: 0.6634 - val_loss: 4.1078 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 516/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9536 - sparse_categorical_accuracy: 0.6747 - val_loss: 4.0607 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 517/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9503 - sparse_categorical_accuracy: 0.6773 - val_loss: 3.9994 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 518/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9941 - sparse_categorical_accuracy: 0.6680 - val_loss: 4.0027 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 519/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9981 - sparse_categorical_accuracy: 0.6608 - val_loss: 4.0968 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 520/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9839 - sparse_categorical_accuracy: 0.6593 - val_loss: 4.0495 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 521/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9578 - sparse_categorical_accuracy: 0.6773 - val_loss: 4.1894 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 522/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9674 - sparse_categorical_accuracy: 0.6783 - val_loss: 4.0966 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 523/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9914 - sparse_categorical_accuracy: 0.6665 - val_loss: 4.0521 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 524/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9500 - sparse_categorical_accuracy: 0.6737 - val_loss: 4.1418 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 525/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0477 - sparse_categorical_accuracy: 0.6490 - val_loss: 4.1251 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 526/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0021 - sparse_categorical_accuracy: 0.6650 - val_loss: 4.0379 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 527/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9769 - sparse_categorical_accuracy: 0.6732 - val_loss: 4.1515 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 528/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9873 - sparse_categorical_accuracy: 0.6629 - val_loss: 4.1086 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 529/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0035 - sparse_categorical_accuracy: 0.6675 - val_loss: 4.1626 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 530/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0160 - sparse_categorical_accuracy: 0.6624 - val_loss: 4.0919 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 531/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9750 - sparse_categorical_accuracy: 0.6680 - val_loss: 4.1525 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 532/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9402 - sparse_categorical_accuracy: 0.6768 - val_loss: 4.2146 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 533/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9569 - sparse_categorical_accuracy: 0.6804 - val_loss: 4.2210 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 534/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9991 - sparse_categorical_accuracy: 0.6650 - val_loss: 4.0467 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 535/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9907 - sparse_categorical_accuracy: 0.6768 - val_loss: 4.0104 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 536/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9537 - sparse_categorical_accuracy: 0.6732 - val_loss: 4.2513 - val_sparse_categorical_accuracy: 0.5165\n",
      "Epoch 537/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9560 - sparse_categorical_accuracy: 0.6722 - val_loss: 4.1750 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 538/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9219 - sparse_categorical_accuracy: 0.6819 - val_loss: 4.0358 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 539/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9085 - sparse_categorical_accuracy: 0.6855 - val_loss: 4.0809 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 540/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9170 - sparse_categorical_accuracy: 0.6824 - val_loss: 4.0486 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 541/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0256 - sparse_categorical_accuracy: 0.6814 - val_loss: 4.1274 - val_sparse_categorical_accuracy: 0.5473\n",
      "Epoch 542/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9636 - sparse_categorical_accuracy: 0.6686 - val_loss: 4.0859 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 543/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9711 - sparse_categorical_accuracy: 0.6763 - val_loss: 4.1369 - val_sparse_categorical_accuracy: 0.5514\n",
      "Epoch 544/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9863 - sparse_categorical_accuracy: 0.6752 - val_loss: 4.3840 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 545/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9982 - sparse_categorical_accuracy: 0.6624 - val_loss: 4.2027 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 546/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9803 - sparse_categorical_accuracy: 0.6665 - val_loss: 4.2065 - val_sparse_categorical_accuracy: 0.5288\n",
      "Epoch 547/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9485 - sparse_categorical_accuracy: 0.6912 - val_loss: 4.2290 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 548/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9518 - sparse_categorical_accuracy: 0.6778 - val_loss: 4.3172 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 549/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9262 - sparse_categorical_accuracy: 0.6845 - val_loss: 4.4382 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 550/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9566 - sparse_categorical_accuracy: 0.6742 - val_loss: 4.4151 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 551/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9711 - sparse_categorical_accuracy: 0.6773 - val_loss: 4.3593 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 552/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0161 - sparse_categorical_accuracy: 0.6742 - val_loss: 4.4635 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 553/3000\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.9520 - sparse_categorical_accuracy: 0.6830 - val_loss: 4.4260 - val_sparse_categorical_accuracy: 0.5144\n",
      "Epoch 554/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9971 - sparse_categorical_accuracy: 0.6809 - val_loss: 4.5065 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 555/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9121 - sparse_categorical_accuracy: 0.6891 - val_loss: 4.3797 - val_sparse_categorical_accuracy: 0.5267\n",
      "Epoch 556/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.8937 - sparse_categorical_accuracy: 0.7005 - val_loss: 4.4529 - val_sparse_categorical_accuracy: 0.5350\n",
      "Epoch 557/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9613 - sparse_categorical_accuracy: 0.6732 - val_loss: 4.3144 - val_sparse_categorical_accuracy: 0.5247\n",
      "Epoch 558/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9207 - sparse_categorical_accuracy: 0.6814 - val_loss: 4.2283 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 559/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9788 - sparse_categorical_accuracy: 0.6722 - val_loss: 4.1972 - val_sparse_categorical_accuracy: 0.5494\n",
      "Epoch 560/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9396 - sparse_categorical_accuracy: 0.6845 - val_loss: 4.2313 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 561/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9962 - sparse_categorical_accuracy: 0.6639 - val_loss: 4.3607 - val_sparse_categorical_accuracy: 0.5535\n",
      "Epoch 562/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9428 - sparse_categorical_accuracy: 0.6794 - val_loss: 4.4423 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 563/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.0230 - sparse_categorical_accuracy: 0.6716 - val_loss: 4.4548 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 564/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9264 - sparse_categorical_accuracy: 0.6845 - val_loss: 4.4735 - val_sparse_categorical_accuracy: 0.5370\n",
      "Epoch 565/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9403 - sparse_categorical_accuracy: 0.6850 - val_loss: 4.5809 - val_sparse_categorical_accuracy: 0.5226\n",
      "Epoch 566/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9718 - sparse_categorical_accuracy: 0.6644 - val_loss: 4.4216 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 567/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9342 - sparse_categorical_accuracy: 0.6722 - val_loss: 4.3863 - val_sparse_categorical_accuracy: 0.5329\n",
      "Epoch 568/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9350 - sparse_categorical_accuracy: 0.6768 - val_loss: 4.3856 - val_sparse_categorical_accuracy: 0.5206\n",
      "Epoch 569/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9911 - sparse_categorical_accuracy: 0.6876 - val_loss: 4.5377 - val_sparse_categorical_accuracy: 0.5309\n",
      "Epoch 570/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9519 - sparse_categorical_accuracy: 0.6773 - val_loss: 4.6212 - val_sparse_categorical_accuracy: 0.5412\n",
      "Epoch 571/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9440 - sparse_categorical_accuracy: 0.6788 - val_loss: 4.3990 - val_sparse_categorical_accuracy: 0.5432\n",
      "Epoch 572/3000\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.9588 - sparse_categorical_accuracy: 0.6845 - val_loss: 4.3105 - val_sparse_categorical_accuracy: 0.5473\n",
      "Epoch 573/3000\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.9871 - sparse_categorical_accuracy: 0.6639 - val_loss: 4.3126 - val_sparse_categorical_accuracy: 0.5185\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=3000,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    # class_weight=class_weight\n",
    ").history\n",
    "\n",
    "# model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "id": "4Ug8HB6kyS2l"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metric = \"sparse_categorical_accuracy\"\n",
    "plt.figure()\n",
    "plt.plot(history[metric])\n",
    "plt.plot(history[\"val_\" + metric])\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "LS7Bp_RRyQFE",
    "outputId": "b2a175bd-6f72-4f42-f57b-8f8125c2db15"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "metric = \"loss\"\n",
    "plt.figure()\n",
    "plt.plot(history[metric])\n",
    "plt.plot(history[\"val_\" + metric])\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "aUlsiHx0ykYy",
    "outputId": "ae05110d-e348-46ec-fc80-c48e3c2c943c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate model"
   ],
   "metadata": {
    "id": "fRMJ4myUy739"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lay8f4aG6GZZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iG0ZSuWy6GZa"
   },
   "outputs": [],
   "source": [
    "def show_confusion(model, validation_dataset):\n",
    "    Y_pred = model.predict(validation_dataset)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_test= np.concatenate([y for x, y in validation_dataset], axis=0)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "    f1_scores = f1_score(y_test, y_pred, average=None)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "    print(f\"\\nF1 scores: {f1_scores}\")\n",
    "    print(f\"\\nMean F1 : {mean_f1}\")\n",
    "    print(f\"\\nAccuracy : {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "6Bawk4k36GZa",
    "outputId": "a1fee861-96ec-4f18-9e64-2e7976a72b67"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4/4 [==============================] - 1s 53ms/step\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "F1 scores: [0.18181818 0.32258065 0.84090909 0.29850746 0.         0.\n",
      " 0.5785124  0.         0.63829787 0.6559633  0.86486486 0.30769231]\n",
      "\n",
      "Mean F1 : 0.390762177076603\n",
      "\n",
      "Accuracy : 0.5637860082304527\n"
     ]
    }
   ],
   "source": [
    "show_confusion(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHhuiG066GZb"
   },
   "outputs": [],
   "source": [
    "# save history\n",
    "with open(\"./dataUsed/historyTrans04\", \"wb\") as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dM7GWTTnB650",
    "outputId": "409a39f6-07c7-4cb8-c4d1-e34d41be0238"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 84). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: modeltrans_allfeat_080/ (stored 0%)\n",
      "  adding: modeltrans_allfeat_080/assets/ (stored 0%)\n",
      "  adding: modeltrans_allfeat_080/variables/ (stored 0%)\n",
      "  adding: modeltrans_allfeat_080/variables/variables.index (deflated 79%)\n",
      "  adding: modeltrans_allfeat_080/variables/variables.data-00000-of-00001 (deflated 9%)\n",
      "  adding: modeltrans_allfeat_080/saved_model.pb (deflated 92%)\n",
      "  adding: modeltrans_allfeat_080/keras_metadata.pb (deflated 95%)\n"
     ]
    }
   ],
   "source": [
    "# save model locally and zipped on drive\n",
    "name = \"./modeltrans_allfeat_080\"\n",
    "model.save(name)\n",
    "!zip -r ./gdrive/MyDrive/ann_dataset/HW2/{name}.zip ./{name}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "dEV6hZ6yxulK",
    "48kdx8F5xw3G",
    "f2_47jejx1mD",
    "mCIAbinC6GY5",
    "t5O5b1ATzG6K",
    "fRMJ4myUy739"
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
